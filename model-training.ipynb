{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d4b4c3",
   "metadata": {},
   "source": [
    "# Steam Review Sentiment\n",
    "\n",
    "A machine learning project to predict Steam game ratings (thumbs up/down) using review text and game metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b544aa",
   "metadata": {},
   "source": [
    "# Data Overview TODO\n",
    "\n",
    "- Our data is using 700 rows with 5 features to determine a Steam game rating.\n",
    "- The data was collected through a script we ran on our local machine to pull data from the `/review` endpoint from the Steam API.\n",
    "- When collecting this data, we did not need to perform any initial transformations\n",
    "\n",
    "#### Details on the data\n",
    "- What is your dependent variable? regression or classification? distribution?\n",
    "    - **Dependent Variable**: The dependent variable is `Recommended`, which indicates whether a review is positive (thumbs up) or negative (thumbs down).\n",
    "    - **Regression or Classification**: This is a `binary classification` problem since the target variable (Recommended) has two possible values: 1 (positive) or 0 (negative).\n",
    "    - **Distribution**: You can check the distribution of the Recommended column to identify class imbalances.\n",
    "\n",
    "### Data Descriptions\n",
    "\n",
    "#### Continuous\n",
    "- `VotesUp`: The number of users that found this review helpful\n",
    "- `VotesFunny`: The number of users that found this review funny\n",
    "- `PlaytimeTotal`: Lifetime playtime tracked in this app\n",
    "- `PlaytimeReview`: Playtime when the review was written\n",
    "- `PlaytimeTwoWeek`: Playtime tracked in the past two weeks for this app\n",
    "- `NumberofReviews`: Number of reviews written by the user\n",
    "- `PostedDate`: Date the review was created (unix timestamp)\n",
    "\n",
    "#### Categorical\n",
    "- `AppID`: The unique id of the game\n",
    "- `GameName`: The name of the reviewed game\n",
    "- `ReviewID`: The unique id of the recommendation\n",
    "- `Author`: The user’s SteamID\n",
    "- `Review`: Text of written review\n",
    "- `Recommended`: True means it was a positive recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224f762",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Import data using pandas. Data imported is in a CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a635d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AppID                  GameName   ReviewID             Author  \\\n",
      "0  3409570            Bricks Smasher  189034666  76561199483805980   \n",
      "1  3409700  Honekawa Marionette Demo  186347944  76561198991875232   \n",
      "2  3409750          Card Draw (Demo)  192050113  76561198973629547   \n",
      "3  3409750          Card Draw (Demo)  191604297  76561198941797474   \n",
      "4  3409750          Card Draw (Demo)  189258437  76561198261537547   \n",
      "\n",
      "                                              Review  Recommended  VotesUp  \\\n",
      "0  Good, clean, silly fun! [i]Bricks Smasher[/i] ...         True        1   \n",
      "1  I loved the art style and music. I love the lo...         True        1   \n",
      "2  Very interesting game. Strategic mode is my fa...         True        1   \n",
      "3  (I've been playing this on itch.io for a while...         True        1   \n",
      "4  Very good game the best mode is strategy I sug...         True        1   \n",
      "\n",
      "   VotesFunny  PlaytimeTotal  PlaytimeReview  PlaytimeTwoWeeks  \\\n",
      "0           0             56            48.0                 0   \n",
      "1           0             57            57.0                 0   \n",
      "2           0            634           357.0               104   \n",
      "3           0            185            55.0                 4   \n",
      "4           0             40            39.0                 1   \n",
      "\n",
      "   NumberofReviews  PostedDate  \n",
      "0               32  1740813811  \n",
      "1                1  1737782504  \n",
      "2                2  1743864215  \n",
      "3                6  1743373022  \n",
      "4                1  1741001983  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Dataset/steamreviews.csv\"\n",
    "steam_reviews = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(steam_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a73fae",
   "metadata": {},
   "source": [
    "## Training TODO\n",
    "\n",
    "10 pts: perform some thoughtful supervised learning, including engineering and selecting features, selecting\n",
    "and optimizing a model, and explaining your model (coeﬃcients or feature importance, performance). Here\n",
    "are some suggested key points.\n",
    "- feature engineering / selection, bivariate charts? Interactions?\n",
    "- missing data? how to handle it?\n",
    "- Selection of modeling algorithm? classification or regression? binary or multi-class?\n",
    "- interpretation of variable importance, coeﬃcients if applicable\n",
    "- justification of choice of metric (accuracy, precision / recall, other?)\n",
    "- is class weighting or over / under sampling appropriate?\n",
    "- discussion of choice or tuning of hyperparameters, if any\n",
    "- meaningful discussion of predictive power and conclusions from model\n",
    "- look at misclassified examples from test dataset, what do they say about your model?\n",
    "- outliers in data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a645fd6c",
   "metadata": {},
   "source": [
    "### Perform some Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44b6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "# Drop rows where Review or Recommended is missing\n",
    "steam_reviews_clean = steam_reviews.dropna(subset=[\"Review\", \"Recommended\"])\n",
    "\n",
    "# Convert 'Recommended' column to binary labels\n",
    "steam_reviews_clean[\"label\"] = steam_reviews_clean[\"Recommended\"].astype(int)\n",
    "\n",
    "# -------- Numeric Features --------\n",
    "numeric_cols = [\"VotesUp\", \"VotesFunny\", \"PlaytimeTotal\", \"PlaytimeTwoWeeks\", \"NumberofReviews\"]\n",
    "X_numeric = steam_reviews_clean[numeric_cols].fillna(0)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# -------- Text Features --------\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X_text = vectorizer.fit_transform(steam_reviews_clean[\"Review\"])\n",
    "\n",
    "# -------- Combine --------\n",
    "X_combined = scipy.sparse.hstack([X_text, X_numeric_scaled])\n",
    "\n",
    "# -------- Labels --------\n",
    "y = steam_reviews_clean[\"label\"].values\n",
    "\n",
    "# -------- Train/Test Split --------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------- Convert to PyTorch Tensors --------\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849749db",
   "metadata": {},
   "source": [
    "### Define Simple Neural Network\n",
    "\n",
    "Details on neural network:\n",
    "- One hidden layer\n",
    "- ReLU activation\n",
    "- Sigmoid output (since it's binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c27c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SteamReviewClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SteamReviewClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize with the correct input size\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = SteamReviewClassifier(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19196a8",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "A simple training loop for several epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe90ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6945\n",
      "Epoch [2/10], Loss: 0.6731\n",
      "Epoch [3/10], Loss: 0.6544\n",
      "Epoch [4/10], Loss: 0.6380\n",
      "Epoch [5/10], Loss: 0.6235\n",
      "Epoch [6/10], Loss: 0.6105\n",
      "Epoch [7/10], Loss: 0.5986\n",
      "Epoch [8/10], Loss: 0.5877\n",
      "Epoch [9/10], Loss: 0.5774\n",
      "Epoch [10/10], Loss: 0.5677\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training loss\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d864007",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d7d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8434343434343434\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.01      0.02        93\n",
      "         1.0       0.84      1.00      0.91       501\n",
      "\n",
      "    accuracy                           0.84       594\n",
      "   macro avg       0.67      0.50      0.47       594\n",
      "weighted avg       0.79      0.84      0.77       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No need to compute gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = model(X_test_tensor)\n",
    "    y_pred = (y_pred_probs >= 0.5).float()\n",
    "\n",
    "# Convert tensors to numpy for reporting\n",
    "y_pred_np = y_pred.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "# Report metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test_np, y_pred_np))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_np, y_pred_np))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf672c1",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "\n",
    "Save model to the onnx format to load it to a JavaScript app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0ab315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, input_dim)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"models/steam_review_model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b266989",
   "metadata": {},
   "source": [
    "## PCA TODO\n",
    "\n",
    "5 pts: PCA as data exploration and visualization. Here are some suggested key points.\n",
    "- take a look at PCA, percent explained\n",
    "- take a look at top eigenvector or two, what is it made out of?\n",
    "- can you visualize your prediction problem by projecting to 2 dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861e25f",
   "metadata": {},
   "source": [
    "## K-means and data exploration TODO\n",
    "\n",
    "5 pts: k-means as data exploration and visualization. Here are some suggested key points.\n",
    "- discussion for choosing number of clusters\n",
    "- analysis of cluster centers\n",
    "- scatter plot(s) showing 2 dimensional perspective of clusters and cluster centers?\n",
    "- meaningful interpretation / discussion of conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
