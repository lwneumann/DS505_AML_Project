{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d4b4c3",
   "metadata": {},
   "source": [
    "# Steam Review Sentiment\n",
    "\n",
    "A machine learning project to predict Steam game ratings (thumbs up/down) using review text and game metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b544aa",
   "metadata": {},
   "source": [
    "# Data Overview TODO\n",
    "\n",
    "- Our data is using 700 rows with 5 features to determine a Steam game rating.\n",
    "- The data was collected through a script we ran on our local machine to pull data from the `/review` endpoint from the Steam API.\n",
    "- When collecting this data, we did not need to perform any initial transformations\n",
    "\n",
    "#### Details on the data\n",
    "- What is your dependent variable? regression or classification? distribution?\n",
    "    - **Dependent Variable**: The dependent variable is `Recommended`, which indicates whether a review is positive (thumbs up) or negative (thumbs down).\n",
    "    - **Regression or Classification**: This is a `binary classification` problem since the target variable (Recommended) has two possible values: 1 (positive) or 0 (negative).\n",
    "    - **Distribution**: You can check the distribution of the Recommended column to identify class imbalances.\n",
    "\n",
    "### Data Descriptions\n",
    "\n",
    "#### Continuous\n",
    "- `VotesUp`: The number of users that found this review helpful\n",
    "- `VotesFunny`: The number of users that found this review funny\n",
    "- `PlaytimeTotal`: Lifetime playtime tracked in this app\n",
    "- `PlaytimeReview`: Playtime when the review was written\n",
    "- `PlaytimeTwoWeek`: Playtime tracked in the past two weeks for this app\n",
    "- `NumberofReviews`: Number of reviews written by the user\n",
    "- `PostedDate`: Date the review was created (unix timestamp)\n",
    "\n",
    "#### Categorical\n",
    "- `AppID`: The unique id of the game\n",
    "- `GameName`: The name of the reviewed game\n",
    "- `ReviewID`: The unique id of the recommendation\n",
    "- `Author`: The user’s SteamID\n",
    "- `Review`: Text of written review\n",
    "- `Recommended`: True means it was a positive recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224f762",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Import data using pandas. Data imported is in a CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a635d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset/steamreviews.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Dataset/steamreviews.csv\"\n",
    "steam_reviews = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(steam_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a73fae",
   "metadata": {},
   "source": [
    "## Training TODO\n",
    "\n",
    "10 pts: perform some thoughtful supervised learning, including engineering and selecting features, selecting\n",
    "and optimizing a model, and explaining your model (coeﬃcients or feature importance, performance). Here\n",
    "are some suggested key points.\n",
    "- feature engineering / selection, bivariate charts? Interactions?\n",
    "- missing data? how to handle it?\n",
    "- Selection of modeling algorithm? classification or regression? binary or multi-class?\n",
    "- interpretation of variable importance, coeﬃcients if applicable\n",
    "- justification of choice of metric (accuracy, precision / recall, other?)\n",
    "- is class weighting or over / under sampling appropriate?\n",
    "- discussion of choice or tuning of hyperparameters, if any\n",
    "- meaningful discussion of predictive power and conclusions from model\n",
    "- look at misclassified examples from test dataset, what do they say about your model?\n",
    "- outliers in data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a645fd6c",
   "metadata": {},
   "source": [
    "### Perform some Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "# Drop rows where Review or Recommended is missing\n",
    "steam_reviews_clean = steam_reviews.dropna(subset=[\"Review\", \"Recommended\"])\n",
    "\n",
    "# Convert 'Recommended' column to binary labels\n",
    "steam_reviews_clean[\"label\"] = steam_reviews_clean[\"Recommended\"].astype(int)\n",
    "\n",
    "# -------- Numeric Features --------\n",
    "numeric_cols = [\"VotesUp\", \"VotesFunny\", \"PlaytimeTotal\", \"PlaytimeTwoWeeks\", \"NumberofReviews\"]\n",
    "X_numeric = steam_reviews_clean[numeric_cols].fillna(0)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# -------- Text Features --------\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X_text = vectorizer.fit_transform(steam_reviews_clean[\"Review\"])\n",
    "\n",
    "# -------- Combine --------\n",
    "X_combined = scipy.sparse.hstack([X_text, X_numeric_scaled])\n",
    "\n",
    "# -------- Labels --------\n",
    "y = steam_reviews_clean[\"label\"].values\n",
    "\n",
    "# -------- Train/Test Split --------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------- Convert to PyTorch Tensors --------\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849749db",
   "metadata": {},
   "source": [
    "### Define Simple Neural Network\n",
    "\n",
    "Details on neural network:\n",
    "- One hidden layer\n",
    "- ReLU activation\n",
    "- Sigmoid output (since it's binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c27c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SteamReviewClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SteamReviewClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize with the correct input size\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = SteamReviewClassifier(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19196a8",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "A simple training loop for several epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training loss\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d864007",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d7d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No need to compute gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = model(X_test_tensor)\n",
    "    y_pred = (y_pred_probs >= 0.5).float()\n",
    "\n",
    "# Convert tensors to numpy for reporting\n",
    "y_pred_np = y_pred.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "# Report metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test_np, y_pred_np))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_np, y_pred_np))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf672c1",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "\n",
    "Save model to the onnx format to load it to a JavaScript app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ab315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, input_dim)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"models/steam_review_model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b266989",
   "metadata": {},
   "source": [
    "## PCA TODO\n",
    "\n",
    "5 pts: PCA as data exploration and visualization. Here are some suggested key points.\n",
    "- take a look at PCA, percent explained\n",
    "- take a look at top eigenvector or two, what is it made out of?\n",
    "- can you visualize your prediction problem by projecting to 2 dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861e25f",
   "metadata": {},
   "source": [
    "## K-means and data exploration TODO\n",
    "\n",
    "5 pts: k-means as data exploration and visualization. Here are some suggested key points.\n",
    "- discussion for choosing number of clusters\n",
    "- analysis of cluster centers\n",
    "- scatter plot(s) showing 2 dimensional perspective of clusters and cluster centers?\n",
    "- meaningful interpretation / discussion of conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2a01e-752a-41a3-a647-30cae21b3389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283ec28-a736-4bda-abe5-9ba120de54b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04f411-bdcf-44cd-b5ce-94b23aac3624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac266f2-e140-4ffd-8cee-a55e814ab123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3671a-05c5-45c9-9cb9-347ceb82099e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a1bd5-0555-4e0c-aefd-35fd48dba285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ab109-c065-4032-8466-291c72c6c121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43840147-0aba-4aa7-86d1-46045d35e2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdb26d-15e3-47a5-b429-bcbbbb92e63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cc5e5-f45d-4721-9afd-7371da176451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56100a5-209d-4042-98de-2fe56eb37b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc79f6-f511-473b-b5d5-628534916f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d35bae-c350-4fe5-ab7e-9d914d8f0e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b9cf2-69fe-4e21-a064-5e6f749afd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "\"Python/Mu (mu_venv-38-20230314-164814)\"",
   "language": "python",
   "name": "mu_venv-38-20230314-164814"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
